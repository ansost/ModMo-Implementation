{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0ae14d",
   "metadata": {},
   "source": [
    "## Data-preprocessing\n",
    "This script preprocesses the data used in Arndt-Lappe 2014. The dataset is given a header and unneccessary information is removed from the dataset:\n",
    "- The number column\n",
    "- The word/phrase column\n",
    "- Comata in the -ity/-ness and word column\n",
    "\n",
    "Current plan for the models:\n",
    "- Model 1\n",
    "    - Cues: Syll1, Syll2, token, syntactical info --> Outcome: suffix\n",
    "- Model 2\n",
    "    - Cues: o1, n1, c1, o2, n2, c2, token, syntactical info --> Outcome: suffix\n",
    "- Model 3\n",
    "    - Cues: o1, n1, c1, o2, n2, c2 (excluding '='), token, syntactical info --> Outcome: suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98949b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from pyndl import count, preprocess\n",
    "#os.chdir('/home/ansost/ModMo-Implementation/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "962659f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'name' parameter adds a header to the file. This is not permanent.\n",
    "df = pd.read_csv('../data/20thcent.txt', \n",
    "                 sep = '\\t', \n",
    "                 names=[\"Outcomes\", \"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \n",
    "                        \"nucleus2\", \"coda2\", \"syntact_info\", \"some_number\", \"token\"])     \n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55175c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas\n",
    "cols_to_replace = [\"Outcomes\", \"token\"]\n",
    "df[cols_to_replace] = df[cols_to_replace].replace({',':''}, regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "059860af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns to be more memory efficient. \n",
    "df.drop(columns=[\"some_number\"], inplace = True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "509da6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the event file for Model1: \n",
    "    # Cues: Syll1, Syll2, token, syntactical info --> Outcome: suffix\n",
    "# Mergin the syllable info together\n",
    "df_m1 = df.copy()\n",
    "df_m1[\"syll1\"] = df_m1[\"onset1\"] + df_m1[\"nucleus1\"] + df_m1[\"coda1\"] \n",
    "df_m1[\"syll2\"] = df_m1[\"onset2\"] + df_m1[\"nucleus2\"] + df_m1[\"coda2\"] \n",
    "df_m1.drop(columns=[\"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \"nucleus2\", \"coda2\"], inplace = True)\n",
    "\n",
    "# Merging columns into 'cues' column\n",
    "df_m1[\"Cues\"] = df_m1[\"syll1\"] + \"_\" + df_m1[\"syll1\"] + \"_\" + df_m1[\"syntact_info\"] + \"_\" + df_m1[\"token\"] \n",
    "df_m1.drop(columns=[\"syll1\", \"syll2\", \"token\", \"syntact_info\"], inplace = True)\n",
    "df_m1 = df_m1[[\"Cues\", \"Outcomes\"]]\n",
    "df_m1.to_csv(\"../data/m1_syllable.tsv\", sep = '\\t', index = False)\n",
    "del df_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "650469f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the event file for Model2: \n",
    "    # Cues: o1, n1, c1, o2, n2, c2, token, syntactical info --> Outcome: suffix\n",
    "df_m2 = df.copy()\n",
    "\n",
    "# Merging columns into 'cues' column\n",
    "df_m2[\"Cues\"] = df_m2[\"onset1\"] + \"_\" + df_m2[\"nucleus1\"] + \"_\" + df_m2[\"coda1\"]  + \"_\" + df_m2[\"onset2\"] + \"_\" + df_m2[\"nucleus2\"]  + \"_\" + df_m2[\"coda2\"]  + \"_\" + df_m2[\"syntact_info\"] + \"_\" + df_m2[\"token\"]\n",
    "df_m2.drop(columns=[\"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \"nucleus2\", \"coda2\", \"syntact_info\", \"token\"], inplace = True)\n",
    "df_m2 = df_m2[[\"Cues\", \"Outcomes\"]]\n",
    "df_m2.to_csv(\"../data/m2_separate.tsv\", sep = '\\t', index = False)\n",
    "del df_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eaf96965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gzip the files\n",
    "with open(\"../data/m1_syllable.tsv\", \"rb\") as f_in, gzip.open(\"../data/m1_syllable.gz\", \"wb\") as f_out:\n",
    "    f_out.writelines(f_in)\n",
    "\n",
    "with open(\"../data/m2_separate.tsv\", \"rb\") as f_in, gzip.open(\"../data/m2_separate.gz\", \"wb\") as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45b38c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the eventfile to make model3 without '='\n",
    "preprocess.filter_event_file(input_event_file=\"../data/m2_separate.gz\",\n",
    "                             output_event_file=\"../data/m3_separate_filtered.gz\",\n",
    "                             remove_cues=('='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write this to a file/table and plot it. \n",
    "freq, cue_freq_map, outcome_freq_map = count.cues_outcomes(event_file_name=\"../data/m3_separate_filtered.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
