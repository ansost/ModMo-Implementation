{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0ae14d",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98949b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from pyndl import count, preprocess\n",
    "#os.chdir('/home/ansost/ModMo-Implementation/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "962659f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in the file with. A header is specified in the 'names' argument since the original file does not have one. \n",
    "# The suffix column is already named 'outcomes' since we dont need to preprocess it and it saves one renaming\n",
    "# operation. \n",
    "df = pd.read_csv('../data/20thcent.txt', \n",
    "                 sep = '\\t', \n",
    "                 names=[\"Outcomes\", \"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \n",
    "                        \"nucleus2\", \"coda2\", \"syntact_info\", \"some_number\", \"token\"])     \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55175c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes commas in Suffix and token columns.\n",
    "cols_to_replace = [\"Outcomes\", \"token\"]\n",
    "df[cols_to_replace] = df[cols_to_replace].replace({',':''}, regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "059860af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns to be more memory efficient. \n",
    "df.drop(columns=[\"some_number\"], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "509da6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1.\n",
    "# Cues: second-to-last syllable (syll1), last syllable (syll2), token, syntactical info, Outcomes: suffix.\n",
    "\n",
    "df_m1 = df.copy()\n",
    "\n",
    "# Merges the syllable info together.\n",
    "df_m1[\"syll1\"] = df_m1[\"onset1\"] + df_m1[\"nucleus1\"] + df_m1[\"coda1\"] \n",
    "df_m1[\"syll2\"] = df_m1[\"onset2\"] + df_m1[\"nucleus2\"] + df_m1[\"coda2\"] \n",
    "df_m1.drop(columns=[\"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \"nucleus2\", \"coda2\"], inplace = True)\n",
    "\n",
    "# Merges columns into 'cues' column.\n",
    "df_m1[\"Cues\"] = df_m1[\"syll1\"] + \"_\" + df_m1[\"syll1\"] + \"_\" + df_m1[\"syntact_info\"] + \"_\" + df_m1[\"token\"] \n",
    "df_m1.drop(columns=[\"syll1\", \"syll2\", \"token\", \"syntact_info\"], inplace = True)\n",
    "df_m1 = df_m1[[\"Cues\", \"Outcomes\"]]\n",
    "df_m1.to_csv(\"../data/m1_syllable.tsv\", sep = '\\t', index = False)\n",
    "del df_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "650469f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2.\n",
    "# Cues: onset 1, nucleus 1, coda 1, onset 2, nucleus 2, coda 2, token, syntactical info, Outcomes suffix.\n",
    "\n",
    "df_m2 = df.copy()\n",
    "\n",
    "# Merges columns into 'cues' column.\n",
    "df_m2[\"Cues\"] = df_m2[\"onset1\"] + \"_\" + df_m2[\"nucleus1\"] + \"_\" + df_m2[\"coda1\"]  + \"_\" + df_m2[\"onset2\"] + \"_\" + df_m2[\"nucleus2\"]  + \"_\" + df_m2[\"coda2\"]  + \"_\" + df_m2[\"syntact_info\"] + \"_\" + df_m2[\"token\"]\n",
    "df_m2.drop(columns=[\"onset1\", \"nucleus1\", \"coda1\", \"onset2\", \"nucleus2\", \"coda2\", \"syntact_info\", \"token\"], inplace = True)\n",
    "df_m2 = df_m2[[\"Cues\", \"Outcomes\"]]\n",
    "df_m2.to_csv(\"../data/m2_separate.tsv\", sep = '\\t', index = False)\n",
    "del df_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eaf96965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gzips the files, needed for pyndl input. \n",
    "with open(\"../data/m1_syllable.tsv\", \"rb\") as f_in, gzip.open(\"../data/m1_syllable.gz\", \"wb\") as f_out:\n",
    "    f_out.writelines(f_in)\n",
    "with open(\"../data/m2_separate.tsv\", \"rb\") as f_in, gzip.open(\"../data/m2_separate.gz\", \"wb\") as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45b38c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3.\n",
    "# Filtering the eventfile to get a model without '=' as a cue.\n",
    "# The pyndl functions only work with g-zipped files. \n",
    "preprocess.filter_event_file(input_event_file=\"../data/m2_separate.gz\",\n",
    "                             output_event_file=\"../data/m3_separate_filtered.gz\",\n",
    "                             remove_cues=('='))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
