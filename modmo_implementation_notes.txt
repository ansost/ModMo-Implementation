RQ: Can NDL model the same effects as TRaml with the same dataset?

---Estimated workflow--------------------------
- delete unnecessary data from 20th cent file
	- 'word', the number column, maybe the comata in the ness/ity 
		and correct word columns
- segment data so it can be made into an event file
	- either look into event file from dataframe
	- or delte/merge columns in a way that fits

OPTION1: Train one model and make a decision

OPTION2: Train two model, structured and unstructured by syllable
	     - e.g. for input: '=	q	=	b	ow	t'
		    Model1: =q=_bowt     --> outcome
		    Model2: =_q_=_b_ow_t --> outcome

- make event files, train model, shouldnt take too long weil kleines
	dataset
- make activation matrix from weight matrix, write function to check 
	for correct predictions with input file
- get some accuracy percentage, entweder fancy F1/F2 oder einfach 
	normale x/All percentage
- Make some plots about cue frequency in R, using input file
	--> frequency influences 'discriminability', wie gut/schlecht 
		das Datenset ist might explain NDL performance
- muse about expected and actual result
	- probably going to perform bad because I expect the cue
		distribution to be not great
- Upload code to GitHub repo + descriptions

---Open questions-----------------------------
- input is probably different than traml, da cues nicht in einer
	Reihenfolge considered werden sondern generally nach
	occurence
	--> wie war das bei traml?
	- wäre ja interessant falls NDL das trotzdem einigermaßen
		modeln kann...
- what about diese gleichzeichen? 
	--> was war das im traml paper?
- some further research directions
	- more spophisticated input, e.g. larger dataset, weighted/
		geordneter input...

